{
  "$schema": "https://opencode.ai/config.json",
  "provider": {
      "ollama": {
          "npm": "@ai-sdk/openai-compatible",
          "name": "Ollama",
          "options": {
              "baseURL": "http://192.168.1.131:11434/v1",
              "num_ctx": 32768
          },
          "models": {
              "gpt-oss:20b-16k-tools": {
                  "name": "GPT-OSS 20B (local, 16k, tools)"
              },
              "gpt-oss:20b": {
                  "name": "GPT OSS:20b (14GB)",
                  "contextWindow": 200000,
                  "maxOutputTokens": 8192
              },
              "llama3.2:3b": {
                  "name": "Llama 3.2 3B",
                  "contextWindow": 32768,
                  "maxOutputTokens": 8192
              },
              "llama3.1:8b": {
                  "name": "Llama 3.1 8B",
                  "contextWindow": 32768,
                  "maxOutputTokens": 8192
              },
              "mistral:7b": {
                  "name": "Mistral 7B",
                  "contextWindow": 32768,
                  "maxOutputTokens": 8192
              },
              "phi4:14b": {
                  "name": "Phi 4 14B",
                  "contextWindow": 16384,
                  "maxOutputTokens": 4096
              },
              "qwen2.5:7b": {
                  "name": "Qwen 2.5 7B",
                  "contextWindow": 32768,
                  "maxOutputTokens": 8192
              },
              "qwen2.5-coder:14b": {
                  "name": "Qwen 2.5 Coder 14B",
                  "contextWindow": 32768,
                  "maxOutputTokens": 8192
              },
              "qwen2.5-coder:7b": {
                  "name": "Qwen 2.5 Coder 7B",
                  "contextWindow": 32768,
                  "maxOutputTokens": 8192
              },
              "codellama": {
                  "name": "Code Llama",
                  "contextWindow": 16384,
                  "maxOutputTokens": 4096
              },
              "deepseek-coder": {
                  "name": "DeepSeek Coder",
                  "contextWindow": 16384,
                  "maxOutputTokens": 4096
              },
              "starcoder2": {
                  "name": "StarCoder 2",
                  "contextWindow": 16384,
                  "maxOutputTokens": 4096
              },
              "llama3.1:70b": {
                  "name": "Llama 3.1 70B",
                  "contextWindow": 32768,
                  "maxOutputTokens": 8192
              },
              "mixtral:8x7b": {
                  "name": "Mixtral 8x7B",
                  "contextWindow": 32768,
                  "maxOutputTokens": 8192
              }
          }
      }
  },
  "agent": {
      "testing-gpt": {
          "description": "Primary coding agent using local GPT-OSS via Ollama.",
          "model": "ollama/gpt-oss:20b-16k-tools",
          "tools": {
              "read": true,
              "write": true,
              "edit": true,
              "bash": true,
              "grep": true,
              "glob": true,
              "list": true,
              "patch": true,
              "todoread": true,
              "todowrite": true,
              "webfetch": true  // often best to start without web tools
          },
          "prompt": "{file:./agent/local-gpt-oss.md}"
      }
  },
  "mcp": {
    "github": {
      "type": "local",
      "command": ["npx", "-y", "@modelcontextprotocol/server-github"],
      "environment": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "{env:GIT_AUTH_TOKEN}"
      },
      "enabled": false
    },
    "context7": {
        "type": "remote",
        "url": "https://mcp.context7.com/mcp",
        "headers": {
            "CONTEXT7_API_KEY": "{env:CONTEXT7_API_KEY}"
        },
        "enabled": true
    },
    "azure-devops": {
      "type": "local",
      "command": ["npx", "-y", "@azure-devops/mcp", "bellefieldsystems"],
      "enabled": false
    },
    "synthia": {
        "type": "local",
        "command": ["node", "/Users/michael.schmitt/sc/hackathon/Synthia/apps/mcp-server/build/index.js"],
        "enabled": false,
        "environment": {
            "USE_API": "true"
        }
    },
    "tts": {
      "type": "local",
      "command": ["mcp-tts", "--suppress-speaking-output"],
      "enabled": true,
      "environment": {
        "ELEVENLABS_API_KEY": "{env:ELEVENLABS_API_KEY}",
        "ELEVENLABS_VOICE_ID": "{env:ELEVENLABS_VOICE_ID}",
        "MCP_TTS_SUPPRESS_SPEAKING_OUTPUT": "true",
        "MCP_TTS_ALLOW_CONCURRENT": "false"
      }
    },
    "puppeteer": {
      "type": "local",
      "command": ["npx", "-y", "@modelcontextprotocol/server-puppeteer"],
      "enabled": true
    },


    "sequential-thinking": {
      "type": "local",
      "command": ["npx", "-y", "@modelcontextprotocol/server-sequential-thinking"],
      "enabled": true
    },
    "figma": {
      "type": "local",
      "command": ["npx", "-y", "figma-developer-mcp", "--stdio"],
      "enabled": false,
      "environment": {
        "FIGMA_API_KEY": "{env:FIGMA_API_KEY}"
      }
    }
  }
}
